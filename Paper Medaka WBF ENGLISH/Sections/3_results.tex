This section provides a concise description of the experimental outcomes, their interpretation, and the main conclusions that can be drawn. The experiments were structured in three stages: (i) fine-tuning of a single YOLOv8 model, (ii) 5-fold cross-validation for generalization assessment, and (iii) an AdaBoost ensemble of the best-performing models. Performance was evaluated using COCO metrics (mAP, precision, recall) and confusion matrices.

\subsection{Experiment 1: YOLOv8 Fine-Tuning}

The first experiment trained YOLOv8 for 100 epochs with a batch size of 16 on the mixed dataset (70\% train, 20\% validation, 10\% test). The following results were obtained:

\begin{itemize}
    \item Precision stabilized at $\sim$0.80;
    \item Recall reached 0.90, indicating reliable detection of both species;
    \item The confusion matrix showed high performance on \textit{O. celebensis} (precision 0.96, recall 0.95), but slightly weaker performance on \textit{O. javanicus} (precision 0.87, recall 0.81).
\end{itemize}

Overall, the single model performed well, but was prone to under-detection of \textit{O. javanicus} in challenging conditions.

\subsection{Experiment 2: 5-Fold Cross-Validation}

To evaluate generalization, the dataset was split into five folds (80\% training, 20\% validation). Each subset served as validation once while the remaining four subsets were used for training.

Key outcomes:
\begin{itemize}
    \item Average mAP@0.5 across folds: 0.78;
    \item Average precision: 0.77; average recall: 0.82;
    \item Model 4 produced the most stable performance across metrics.
\end{itemize}

This confirms that YOLOv8 can generalize well to unseen Medaka fish images, mitigating overfitting risks.

\subsection{Experiment 3: Ensemble with AdaBoost}

An ensemble was created using the five cross-validated models with AdaBoost weighting. Models with higher error received greater weight in subsequent iterations.

The ensemble showed clear improvements:
\begin{itemize}
    \item mAP@0.5 improved to 0.81 (from 0.78 in cross-validation);
    \item mAP@0.5:0.95 improved to 0.63;
    \item Precision increased to 0.82; recall to 0.86.
\end{itemize}

The ensemble was especially effective in reducing misclassifications of small or occluded fish.

\subsection{Figures, Tables and Schemes}

The dataset composition is summarized in Table~\ref{tab:data_sources}, and sample annotated images are shown in Figure~\ref{fig:dataset_hybrid}. Model training dynamics (loss curves, precision-recall plots) are presented in Figures~\ref{fig:exp1_curve}â€“\ref{fig:exp2_error_class_loss}, while ensemble performance is summarized in Figure~\ref{fig:ensemble_results}.

\begin{table}[H]
\caption{Dataset distribution of Medaka fish images.}
\label{tab:data_sources}
\begin{tabularx}{\textwidth}{lCCC}
\toprule
\textbf{Species} & \textbf{Primary Data} & \textbf{Secondary Data} & \textbf{Total}\\
\midrule
\textit{O. javanicus} & 257 & 178 & 435 \\
\textit{O. celebensis} & 287 & 70  & 357 \\
\midrule
\textbf{Total} & \textbf{544} & \textbf{248} & \textbf{792} \\
\bottomrule
\end{tabularx}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{Images/dataset_hybrid.jpg}
\caption{Examples of annotated Medaka images from the mixed dataset.}
\label{fig:dataset_hybrid}
\end{figure}