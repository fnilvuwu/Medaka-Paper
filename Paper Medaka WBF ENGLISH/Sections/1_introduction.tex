% The advancement of artificial intelligence (AI) has significantly contributed to wildlife conservation efforts, particularly in automating species identification and monitoring. These technologies are invaluable in environments where manual observation is difficult, such as underwater ecosystems, where factors like turbidity and low light complicate visibility \citep{LeCun2015, Liu2019}. AI-based systems can process extensive volumes of visual data from images and videos to assist in detecting species presence, tracking their behavior, and supporting conservation strategies with minimal human intervention \citep{Kalafi2018}.

% In this context, object detection models have gained traction for their speed and efficiency in real-time applications. The You Only Look Once (YOLO) architecture, particularly its latest version, YOLOv8, enhances prior iterations with improved accuracy and architectural efficiency, making it suitable for challenging tasks like aquatic species recognition. YOLOv8 effectively counters issues surrounding image degradation commonly faced underwater, such as turbidity, unfavorable lighting, and occlusion \citep{Redmon2017}.

% Our study specifically targets the detection of two notable Medaka fish species—\textit{Oryzias javanicus} and \textit{Oryzias celebensis}. These species pose unique monitoring challenges due to their dwindling populations and the complexities of underwater imaging. To bolster this investigation, we constructed a custom dataset comprising both manually collected images using cameras and publicly available images from internet resources. This dataset contains a total of 2,016 images, segregated into 1,857 images (92\%) for training and 159 images (8\%) for testing. We utilized Roboflow for manual annotation of the dataset, alongside conducting essential preprocessing and augmentation \citep{Dang2020}.

% The preprocessing steps involved automatic orientation adjustments, resizing images to a standard 640×640 pixels, and filtering out any empty annotations. To enhance the robustness of the model and improve generalization, augmentations such as horizontal and vertical flips, as well as rotations (90°, 180°, and 270°), were applied \citep{Arbogast2016}. These methodological choices mitigate the risks of overfitting and aim to simulate various real-world conditions that the model may encounter.

% For the detection task, we employed a YOLOv8-based approach featuring 5-fold cross-validation to train five individual models. Predictions from these distinct models were subsequently refined and combined using Weighted Box Fusion (WBF), an advanced ensemble method that enhances final bounding boxes by evaluating confidence scores and overlaps—ultimately bolstering the model's overall detection performance \citep{Solovyev2021, Leow2015}. Our findings indicate that this ensemble approach achieves a substantial increase in mean Average Precision (mAP) relative to a single YOLOv8 model. Notably, while ensemble methods do increase inference time, they significantly enhance the model's robustness, especially when detecting small or less visible targets such as Medaka fish. Through this research, we establish a foundational reference for the development of lightweight ensemble methodologies applicable to underwater object detection, utilizing advanced real-time detection models \citep{Salimi2016}. 

The rapid advancement of artificial intelligence (AI) has greatly influenced wildlife conservation, particularly by enabling automated systems for species identification and monitoring. Such technologies are especially valuable in environments where direct human observation is challenging, including underwater ecosystems where visibility is often compromised by turbidity, low illumination, and other environmental constraints \citep{LeCun2015, Liu2019}. AI-driven approaches can process vast volumes of visual data from images and videos, supporting the detection of species, tracking behavioral patterns, and assisting conservation efforts with minimal human intervention \citep{Kalafi2018}.

Among various AI techniques, object detection models have gained prominence due to their ability to operate with high speed and efficiency, making them suitable for real-time ecological applications. The You Only Look Once (YOLO) family of models, particularly its most recent iteration YOLOv8, has advanced earlier architectures by improving accuracy and efficiency, making it well-suited for complex tasks such as aquatic species recognition. This framework effectively addresses challenges common in underwater imagery, including image degradation, turbidity, unfavorable lighting, and partial occlusion \citep{Redmon2017}.

In this research, we focus on two endangered Medaka fish species—\textit{Oryzias javanicus} and \textit{Oryzias celebensis}. Both species present unique monitoring challenges due to their decreasing populations and the complexity of capturing reliable underwater images. To support this work, we developed a dataset composed of manually collected images using cameras, combined with publicly available images from online sources. The dataset includes a total of 2,016 images, divided into 1,857 images (92\%) for training and 159 images (8\%) for testing. All images were manually annotated using Roboflow, and further preprocessing and augmentation techniques were applied \citep{Dang2020}.

The preprocessing phase involved automatic orientation correction, resizing images to 640 × 640 pixels, and discarding empty annotations. To enhance robustness and reduce overfitting risks, various augmentations such as horizontal and vertical flips and rotations of 90°, 180°, and 270° were performed \citep{Arbogast2016}. For detection tasks, YOLOv8 was trained using a 5-fold cross-validation approach, producing five independent models. Predictions from these models were then refined using Weighted Box Fusion (WBF), an ensemble method that integrates overlapping bounding boxes based on confidence scores, thereby improving detection accuracy \citep{Solovyev2021, Leow2015}. Our results demonstrate that this ensemble strategy significantly increased mean Average Precision (mAP) compared to single-model baselines. While ensemble approaches introduce additional computational overhead, they substantially improve robustness, particularly in detecting small or partially visible Medaka fish. This study provides a solid foundation for future development of lightweight ensemble strategies tailored to underwater object detection, thereby supporting advanced biodiversity monitoring and conservation initiatives \citep{Salimi2016}.