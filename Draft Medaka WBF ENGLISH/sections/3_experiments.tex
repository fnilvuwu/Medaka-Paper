\section{Experiments}
    \subsection{Experimental environment and parameter configuration}
    % TODO
    The experimental setup for this study utilized an NVIDIA GeForce
    RTX4080 GPU with 16GB of memory, Python 3.8.18, PyTorch 1.7.1
    framework, and CUDA 12.0. The training is performed using a homemade wildlife dataset, and the experimental parameters are shown in
    Table 2.

    \subsection{Evaluation index}
    % TODO
    (1) Precision evaluation metrics: Precision (P), Recall (R), mean
    Average Precision (mAP), and F1 score. mAP@0.5 and mAP@0.5–0.95
    denote the mAP value at an IoU threshold of 0.5 and the average mAP
    value as the IoU ranges from 0.5 to 0.95 with a step size of 0.05,
    respectively. The formulas for each index are shown in Eqs. 12–15,
    where TP represents the number of true positive predictions, FP denotes
    the number of false positive predictions, and FN signifies the number of
    false negative predictions. (2) Speed evaluation metrics: inference time
    (time from preprocessed image input into the model to model output
    result), post-processing time, floating-point operations(GFLOPs), model
    size, and parameter.
    P = TP
    TP + FP (12)
    R = TP
    TP + FN
    
    \subsection{Experiment 1: Fine-Tuning YOLOv8}
    The first experiment was conducted by applying fine-tuning to the YOLOv8 model. YOLOv8 is one of the latest object detection models designed to detect and classify objects in real-time. In this experiment, the pre-trained YOLOv8 model was fine-tuned to the collected Medaka fish dataset. Fine-tuning involves adjusting the pre-trained weights using the Medaka fish data to allow the model to recognize the unique features of the species. \textit{Oryzias javanicus} and \textit{Oryzias celebensis}.
    
    The fine-tuning process is performed using a dataset that has been prepared through preprocessing and augmentation stages, with optimal hyperparameter settings. The goal of this experiment is to improve the accuracy of fish species detection and classification by using the knowledge gained from large datasets and adapting it to more specific datasets.
    
    Fine-tuning the YOLOv8 model is a crucial step to adapt the model's performance to the specific characteristics of the dataset used in this study. YOLOv8, as one of the most advanced object detection algorithms today, requires a fine-tuning process to optimize its ability to detect rare or endangered species. In this process, the pre-trained weights of the model were adjusted using training data from the mixture dataset we collected, which is a combination of primary and secondary data.
    
    The fine-tuning process allows the model to learn unique features of our dataset, such as specific environmental variations, lighting conditions, as well as special traits present in the target species. By applying an approach where some network layers remain frozen while other layers are updated, we were able to utilize the general knowledge gained from the large-scale dataset while still tailoring the model to the unique characteristics of this dataset. This strategy is important for improving detection accuracy, reducing the risk of overfitting, and ensuring the model is reliable in various environmental conservation scenarios.
    
    In this study, the YOLOv8 model is fine-tuned using a mixture dataset that has been divided into 80\% for training data, 20\% for testing data. The model was trained with optimally tuned hyperparameters, namely for 100 epochs, using a batch size of 16, with an automatic optimizer, and a learning rate of 0.01. The model training lasted for approximately 2 hours, utilizing GPU-based computing infrastructure to speed up the process.
    
    \subsection{Experiment 2: 5-Fold Cross Validation}
    In the second experiment, the model was evaluated using the 5-fold cross validation technique. Cross-validation is a method used to ensure that the model has stable performance and can be generalized to various subsets of data. In 5-fold cross-validation, the train data is divided into five subsets, where at each iteration, four subsets are used to train the model, and one subset is used for validation. This process is repeated five times so that each subset serves as a validation set once.
    
    The results of each iteration are then averaged to obtain more accurate performance metrics, such as precision, recall, and mean average precision (mAP). By using cross-validation, the risk of overfitting the model can be minimized, allowing the model to perform optimally on unseen data.
    
    Cross-validation is used to evaluate the reliability and generalizability of YOLOv8 model performance. In this study, we applied 5-fold cross-validation, where the dataset is divided into five subsets (folds). At each iteration, the model is trained using four subsets and tested on the remaining subset. This process is repeated five times, with each fold acting as a one-time validation set. Performance metrics, such as precision, recall, and mean average precision (mAP), are calculated at each iteration and then averaged to provide an accurate and reliable estimate of the model's overall capability.
    
    Cross-validation is important to reduce the risk of overfitting, because by dividing the data into multiple subsets and testing the model iteratively, we can ensure that the model performs consistently even if the data is divided in different ways. It also helps in ensuring that the model is more resilient to variations in the dataset and reliable when applied to data outside the training sample.
    
    In this research, the dataset is divided into 80\% (508 images) for the training set and 20\% (158 images) for the test set. The training set was further divided into five subsets (A, B, C, D, and E), each containing 127 images. The model was trained using four subsets as training set and one subset as validation set at each iteration. This training process was repeated five times, rotating among the five subsets. Illustration of experiment 2 or cross validation as shown in {Figure 2}.

    \begin{figure*}[ht]
        \centering
        \includegraphics[width=100mm]{image/Diagram5FoldCrossValidationMethodBlocks.png} 
        \vspace{-6mm}
        \caption{5-Fold Cross Validation}
        \label{fig:foldCrossValidation}
    \end{figure*}

    The model was trained using optimally tuned hyperparameters for 100 epochs, with batch size 16, auto optimizer, and learning rate 0.01. Each training iteration took about 2 hours, so the total time required to complete five cross-validations was approximately 10 hours.
    
    \subsection{Experiment 3: Ensemble Method (ADABoost)}
    The third experiment involved applying ensemble methods to further improve detection and classification performance. The method used is AdaBoost, an ensemble algorithm that works by combining multiple models to improve prediction accuracy. In this approach, the YOLOv8 model is combined with several other models, or variations of the YOLOv8 model with different hyperparameter settings, to form an ensemble system.
    
    The main motivation for using AdaBoost is to improve model performance by correcting the weaknesses of individual models that may fail to recognize certain patterns. The AdaBoost algorithm gives greater weight to the prediction errors of the previous model, so that the next iteration of the model focuses more on correcting those errors. In this way, the resulting model is more robust and accurate, and has a better ability to generalize predictions, even on complex or variable data.
    
    Ensemble learning is a technique used to improve model performance by combining predictions from multiple models. In this study, we apply an ensemble approach by combining multiple YOLOv8 models, where each model is trained with slightly different hyperparameters or trained on different subsets of data. The purpose of this ensemble is to reduce the variance and bias that may exist in each individual model, resulting in more accurate and reliable predictions. This ensemble approach can be done by averaging outputs (such as bounding box coordinates and confidence scores) or using a majority voting mechanism for classification. This technique helps improve overall robustness and predictive ability, especially when dealing with real-world data complexity and diversity.
    
    Experiments using the ADABoost ensemble technique were conducted by utilizing 5 models from the cross validation results in experiment 2. The ADABoost algorithm is as follows

    \begin{table*}[ht]
    \centering
        \begin{tabular}{l}
        \hline \vspace{-1mm} \\
        \vspace{1mm} \textbf{Algorithm: AdaBoost} \vspace{1mm} \\
        \hline \\
            \begin{tabular}[c]{@{}l@{}}
                1. \textbf{Input}: Dataset $D = \{(x_1, y_1), (x_2, y_2), \ldots ,(x_n, y_n)\}$,\\ 
                \qquad \qquad \quad Learner $\Gamma$ and the number of learning iteration $T$\\
                \vspace{-2mm} \\
                2. Initialize weight sample $w_i = \frac{1}{N}, \forall i = 1, 2, \ldots, N$ \\ \vspace{-2mm} \\
              
                3. Iterate, \textbf{for} $t=1 \textbf{ to } T$ \textbf{do} \\ \vspace{-2mm} \\
                \qquad (a) Train a weak learner $h_t$ from $D_t (\in D)$ to train sample $w_i$. %\\
                $h_t = \Gamma \left(D, D_t \right)$ \\ \vspace{-2mm} \\
                % \qquad \qquad \qquad \qquad $h_t = \Gamma \left(D, D_t \right)$ \\ \vspace{-2mm} \\               
                \qquad (b) Compute error of $h_t$:
                %\qquad \qquad \qquad \qquad 
                $\varepsilon_t = \frac{\sum_{i=1}^N w_i \cdot I \left( h_t \left( x_i \right) \neq y_i \right)}{\sum_{i=1}^N w_i}$ \\ \vspace{-1mm} \\
                
                \qquad (c) Compute the weight of $h_t$:
                %\qquad \qquad \qquad \qquad 
                $\alpha_t = \frac{1}{2}\ln\left( \frac{1-\varepsilon_t}{\varepsilon_t} \right)$ \\ \vspace{-2mm} \\
                
                \qquad (d) Assign: $w_i \leftarrow w_i \cdot e^{\left( \alpha_t \cdot I \left( h_t \left( x_i \right) \neq y_i \right)\right)}$ \\ \vspace{-2mm} \\
                
                4. \textbf{Output:} $H(x) = \text{sign} \sum_{t=1}^T \left(\alpha_t \cdot h_t (x)\right)  $ \\
                \vspace{1mm}
            \end{tabular} \\ 
        \hline
        \end{tabular}
    \end{table*}

    \begin{table*}[ht]
        \centering
        \caption{table}
        \vspace{3mm}
        \begin{tabular}{ccc}
            \toprule
            \textbf{Fine-Tuning} & \multicolumn{1}{c}{\textbf{Cross Validation}} & \multicolumn{1}{c}{\textbf{Ensemble (AdaBoost)}} \\ \midrule
            \includegraphics[width=45mm]{image/fine_tuning.png} & 
            \includegraphics[width=45mm]{image/cross_validation.png} & 
            gambar  \\
            \bottomrule
        \end{tabular}
    \end{table*}
